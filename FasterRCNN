# https://www.youtube.com/watch?v=4yOcsWg-7g8&t=4s
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
import matplotlib.pyplot as plt
import numpy as np
import cv2 
from PIL import Image

device = 'cuda' if torch.cuda.is_available() else 'cpu'

# Step 1: Use VGG 16 (or other image classifiers e.g. Resnet50) to extract features from image
model = torchvision.models.vgg16(pretrained=True).to(device)
# Review layers of VGG16
fe = list(model.features)
print(len(fe))

# Step 2: we have 3x800x800 (e.g.) as input. We want to perform subsampling (reduce size, increase depth)
# s.t. we get a 512x50x50, thus, we use all the layers up until that point in vgg
dummy_img = torch.zeros((1,3,800,800)).float()

req_features = []
k = dummy_img.clone().to(device)
for i in fe:
    k = i(k)
    print("k is",k.shape[2])
    if k.shape[2] < 50: #800//16 = 50
        break
    req_features.append(i)
    out_channels = k.size()[1]

print(len(req_features))    
print(out_channels)
# Until layer 30 the feature size is is larger than 50

# Convert the layers into a sequential module
faster_rcnn_fe_extractor = nn.Sequential(*req_features)

